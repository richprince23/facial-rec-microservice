<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Video Recognition</title>
    <style>
        #video {
            width: 640px;
            height: 480px;
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <h1>Live Video Recognition</h1>
    <select id="cameraSelect">
        <option value="">Select a camera</option>
    </select>
    <video id="video" autoplay></video>

    <div>
        <p>Last Recognized : <b id="student_id"></b></p>
    </div>
    <script>
        const studentId = document.getElementById('student_id');
        const video = document.getElementById('video');
        const cameraSelect = document.getElementById('cameraSelect');
        const canvas = document.createElement('canvas');
        canvas.width = 640;
        canvas.height = 480;
        const ctx = canvas.getContext('2d');

        let stream;
        let recognitionInterval;

        // Populate the camera selection dropdown
        async function populateCameraOptions() {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const videoDevices = devices.filter(device => device.kind === 'videoinput');
            videoDevices.forEach(device => {
                const option = document.createElement('option');
                option.value = device.deviceId;
                option.text = device.label || `Camera ${cameraSelect.length + 1}`;
                cameraSelect.appendChild(option);
            });
        }

        // Start the video stream with the selected camera
        async function startVideoStream(deviceId) {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            const constraints = {
                video: {deviceId: deviceId ? {exact: deviceId} : undefined}
            };
            try {
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                await video.play();
                startRecognition();
            } catch (error) {
                console.error('Error accessing the camera:', error);
            }
        }

        // Start the recognition process
        function startRecognition() {
            if (recognitionInterval) {
                clearInterval(recognitionInterval);
            }
            recognitionInterval = setInterval(() => {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                canvas.toBlob(blob => {
                    const formData = new FormData();
                    formData.append('image', blob, 'frame.jpg');
                    fetch('/recognize', {
                        method: 'POST',
                        body: formData
                    })
                    .then(response => response.json())
                    .then(data => {
                        if (data.status === 'success') {
                            console.log(`Recognized face: ${data.student_id}`);
                            studentId.innerText = data.student_id;
                        } else {
                            console.log('No match found');
                        }
                    })
                    .catch(error => console.error('Error:', error));
                }, 'image/jpeg');
            }, 3000);
        }

        // Event listener for camera selection
        cameraSelect.addEventListener('change', (event) => {
            if (event.target.value) {
                startVideoStream(event.target.value);
            }
        });

        // Initialize
        populateCameraOptions().then(() => {
            if (cameraSelect.options.length > 1) {
                cameraSelect.selectedIndex = 1;
                startVideoStream(cameraSelect.value);
            }
        });
    </script>
</body>
</html>